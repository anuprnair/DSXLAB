{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ML Notebook for Banking Churn Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing project and environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.SparkContext\n",
    "import org.apache.spark.SparkConf\n",
    "\n",
    "sc.stop()\n",
    "val conf1 = new SparkConf().setAppName(\"spark_context\").setMaster(\"local[*]\")\n",
    "val scl = new SparkContext(conf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> Note: Only run the cell above when you run this notebook the first time after you create it, or whenever you restart the kernel. If there is error about \"Only one SparkContext may be running in this JVM\", that is expected.</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Brunel and ML Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%AddJar -magic https://brunelvis.org/jar/spark-kernel-brunel-all-2.3.jar -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "//import libraries\n",
    "import org.apache.spark.{SparkConf, SparkContext, SparkFiles}\n",
    "import org.apache.spark.sql.{SQLContext, SparkSession, Row}\n",
    "import org.apache.spark.SparkFiles\n",
    "\n",
    "import org.apache.spark.ml.feature.{StringIndexer, IndexToString, VectorIndexer, VectorAssembler}\n",
    "import org.apache.spark.ml.regression.LinearRegression\n",
    "import org.apache.spark.ml.classification.{LogisticRegression, DecisionTreeClassifier}\n",
    "import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\n",
    "import org.apache.spark.ml.{Pipeline, PipelineStage}\n",
    "import org.apache.spark.ml.ibm.transformers.RenameColumn\n",
    "\n",
    "import com.ibm.analytics.ngp.ingest.Sampling\n",
    "//import com.ibm.analytics.ngp.pipeline._\n",
    "import com.ibm.analytics.ngp.util._\n",
    "import com.ibm.analytics.ngp.pipeline.evaluate.{Evaluator,MLProblemType}\n",
    "\n",
    "import com.ibm.analytics.wml.{Learner, Target}\n",
    "import com.ibm.analytics.wml.cads.CADSEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data from HortonWorks Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// TODO:  Insert \"cust_summary_notebook_training\" remote data set as Spark DataFrame\n",
    "// TODO:  Change the automatically inserted code to use \"scl\" instead of \"sc\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// TODO: Rename the dataframe in the statement below to match the dataframe automatically inserted above\n",
    "val churnDataRaw = df1\n",
    "\n",
    "\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.functions._ \n",
    "\n",
    "val toDouble = udf {churn: Boolean => (if(churn) 1.0 else 0.0)}\n",
    "\n",
    "val churnData = churnDataRaw.select(\"AGE\", \"ACTIVITY\", \"EDUCATION\", \"GENDER\", \"STATE\", \"NEGTWEETS\", \"INCOME\", \"CHURN\").\n",
    "                             withColumn(\"label\", toDouble(churnDataRaw.col(\"CHURN\"))).\n",
    "                             drop(\"CHURN\")\n",
    "churnData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val train = 70\n",
    "val test = 15\n",
    "val validate = 15\n",
    "\n",
    "//Split the data into training data set, testing data set, and validation data set\n",
    "\n",
    "val splits = Sampling.trainingSplit(churnData, train, test, validate)\n",
    "\n",
    "val trainingDF = splits._1\n",
    "val testDF = splits._2\n",
    "val validationDF = splits._3\n",
    "\n",
    "println(\"Training data set\")\n",
    "trainingDF.show(5)\n",
    "\n",
    "println(\"Testing data set\")\n",
    "testDF.show(5)\n",
    "\n",
    "println(\"Validation data set\")\n",
    "validationDF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and Evaluating LR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "//Feature definition\n",
    "\n",
    "val genderIndexer = new StringIndexer().setInputCol(\"GENDER\").setOutputCol(\"gender_code\")\n",
    "val stateIndexer = new StringIndexer().setInputCol(\"STATE\").setOutputCol(\"state_code\")\n",
    "val educationIndexer = new StringIndexer().setInputCol(\"EDUCATION\").setOutputCol(\"education_code\")\n",
    "\n",
    "val featuresAssembler = new VectorAssembler().setInputCols(Array(\"AGE\", \n",
    "                                                         \"ACTIVITY\", \n",
    "                                                         \"education_code\", \n",
    "                                                         \"NEGTWEETS\", \n",
    "                                                         \"INCOME\",\n",
    "                                                         \"gender_code\",\n",
    "                                                         \"state_code\")).setOutputCol(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "//Logistic Regression\n",
    "val lr = new LogisticRegression().setRegParam(0.01).setLabelCol(\"label\").setFeaturesCol(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.{Pipeline, PipelineStage}\n",
    "\n",
    "val pipeline = new Pipeline().setStages(Array(genderIndexer, \n",
    "                                              stateIndexer, \n",
    "                                              educationIndexer,\n",
    "                                              featuresAssembler,\n",
    "                                              lr))\n",
    "val newModel = pipeline.fit(trainingDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.classification.{BinaryLogisticRegressionSummary, LogisticRegressionModel}\n",
    "\n",
    "// Extract the summary from the LogisticRegressionModel instance \n",
    "val lrModel = newModel.stages(4).asInstanceOf[LogisticRegressionModel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.mllib.evaluation.MulticlassMetrics\n",
    "import org.apache.spark.mllib.regression.LabeledPoint\n",
    "\n",
    "val testDFWithPredictions = newModel.transform(testDF)\n",
    "val testData = testDFWithPredictions.drop(\"prediction\", \"rawPrediction\", \"probability\")\n",
    "val trainingSummary = lrModel.evaluate(testData)\n",
    "val binarySummary = trainingSummary.asInstanceOf[BinaryLogisticRegressionSummary]\n",
    "\n",
    "// The ROC curve and area under the ROC curve on test data\n",
    "val rocOnTestData = binarySummary.roc\n",
    "println(s\"Area under ROC curve for the initial model: ${binarySummary.areaUnderROC}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying the evaluation results - ROC curve with Brunel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%brunel data('rocOnTestData') x(FPR) y(TPR) line tooltip(#all) axes(x:'False Positive Rate':grid, y:'True Positive Rate':grid) title('ROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Publish Locally - Use repository service to save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// TODO:  Rename two values in code below to replace the label TODO_CHANGE_TO_TEAMNAME with your lab team's name \n",
    "\n",
    "// DSX Local Machine Learning - Use Repository service to save model.\n",
    "\n",
    "import com.ibm.analytics.ngp.repository.MLRepositoryClient\n",
    "import com.ibm.analytics.ngp.repository.MLRepositoryArtifact\n",
    "\n",
    "val ml_repository_client = MLRepositoryClient()\n",
    "val model_artifact = MLRepositoryArtifact(newModel, trainingDF, \"TODO_CHANGE_TO_TEAMNAME Banking Churn Notebook Model(LR)\")\n",
    "\n",
    "//Add creater information for model\n",
    "val meta_with_author = model_artifact.meta.add(\"authorName\", \"TODO_CHANGE_TO_TEAMNAME\");\n",
    "val mutableArtifact = MLRepositoryArtifact.mutableModelArtifact(model_artifact);\n",
    "val new_artifact = mutableArtifact.mutate(newModel, meta_with_author);\n",
    "\n",
    "val saved_model = ml_repository_client.models.save(new_artifact).get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Locally:  Create online deployment of published model in DSX Local ML Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// TODO:  Rename one value in code below to include your lab team's name, look for TODO_CHANGE_TO_TEAMNAME\n",
    "\n",
    "//DSX Local Machine Learning - Use Deployment service\n",
    "\n",
    "import play.api.libs.json._\n",
    "import scalaj.http.{Http, HttpOptions}\n",
    "\n",
    "val model_version_href = saved_model.meta.prop(\"modelVersionHref\").get\n",
    "val loaded_model_artifact = ml_repository_client.models.version(model_version_href).get\n",
    "val payload_artifactVersionHref = loaded_model_artifact.meta.prop(\"modelVersionHref\").get\n",
    "\n",
    "val payload_name = \"TODO_CHANGE_TO_TEAMNAME Banking Churn Notebook Model (LR) Deployment\"\n",
    "\n",
    "val payload_data_online = Json.stringify(Json.toJson(Map(\"artifactVersionHref\" -> payload_artifactVersionHref, \"name\" -> payload_name)))\n",
    "val service_path = \"https://internal-nginx-svc.ibm-private-cloud.svc.cluster.local:12443\"\n",
    "val online_path = service_path + \"/v2/deployments\"\n",
    "\n",
    "val response_online = Http(online_path).postData(payload_data_online).header(\"Content-Type\", \"application/json\").option(HttpOptions.connTimeout(10000)).option(HttpOptions.readTimeout(50000)).asString\n",
    "\n",
    "print (response_online)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use DSX Local scoring service to classify data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val scoring_href_json: JsValue = Json.parse(response_online.body)\n",
    "val scoring_href = (scoring_href_json \\ \"entity\" \\ \"predictionEndpoints\" \\ \"online\").asOpt[String] match {\n",
    "    case Some(x) => x\n",
    "    case None => \"\"\n",
    "}\n",
    "\n",
    "print(scoring_href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val fields_json =  Json.toJson(List(Json.toJson(\"AGE\"), \n",
    "                                    Json.toJson(\"ACTIVITY\"), \n",
    "                                    Json.toJson(\"EDUCATION\"), \n",
    "                                    Json.toJson(\"GENDER\"), \n",
    "                                    Json.toJson(\"STATE\"),\n",
    "                                    Json.toJson(\"NEGTWEETS\"), \n",
    "                                    Json.toJson(\"INCOME\")))\n",
    "val record_json = Json.toJson(List(Json.toJson(List(Json.toJson(23), \n",
    "                                                    Json.toJson(3), \n",
    "                                                    Json.toJson(\"Masters degree\"), \n",
    "                                                    Json.toJson(\"M\"), \n",
    "                                                    Json.toJson(\"NY\"), \n",
    "                                                    Json.toJson(7), \n",
    "                                                    Json.toJson(878657)))))\n",
    "val json_map = Json.toJson(Map(\"fields\" -> fields_json, \"records\" -> record_json))\n",
    "print(json_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val payload_scoring = Json.stringify(json_map)\n",
    "val response_scoring = Http(scoring_href).postData(payload_scoring).header(\"Content-Type\", \"application/json\").option(HttpOptions.method(\"POST\")).asString\n",
    "print(response_scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Optional - Remaining steps require WML service and credentials to Publish, Deploy, and Score using WML Cloud Service *  \n",
    "*Code below is based on the following documentation and examples:*\n",
    "\n",
    "https://apsportal.ibm.com/analytics/notebooks/c8652d2c-bfc9-4354-8168-f1c9f7f8dfc2/view?access_token=02a83fea8450a452c8de76af98dae078459d0f56810ddef4f4c62d5bc4fc72cf&cm_mc_uid=40662902271614933277870&cm_mc_sid_50200000=1503946544)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First step:  Save model to WML service in IBM Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// TODO:  This lab step is optional, do not run this cell unless you have WML credentials and have updated the credentials below.\n",
    "\n",
    "// WML client library\n",
    "import com.ibm.analytics.ngp.repository.MLRepositoryClient\n",
    "import com.ibm.analytics.ngp.repository.MLRepositoryArtifact\n",
    "\n",
    "// Helper libraries\n",
    "\n",
    "import scalaj.http.{Http, HttpOptions}\n",
    "import scala.util.{Success, Failure}\n",
    "import java.util.Base64\n",
    "import java.nio.charset.StandardCharsets\n",
    "import play.api.libs.json._\n",
    "\n",
    "// Authenticate to Watson Machine Learning service on IBM Cloud.  These values come from \"Service Credentials\" tab in IBM Cloud WML service\n",
    "val service_path = \"https://ibm-watson-ml.mybluemix.net\"\n",
    "\n",
    "// Your Team's WML Creds - update these credentials with your personal WML credentials, **the values below are not valid**\n",
    "val instance_id = \"4de7exyz-6af1-4f1e-8aaf-561a6eb44xyz\"\n",
    "val username = \"8bdcaxyz-b2c9-4579-bb95-ec552d050xyz\"\n",
    "val password = \"8182bxyz-bba1-4154-919c-4bc6113f6xyz\"\n",
    "\n",
    "val client = MLRepositoryClient(service_path)\n",
    "client.authorize(username, password)\n",
    "\n",
    "// Save model\n",
    "val model_artifact = MLRepositoryArtifact(newModel, trainingDF, \"From DSX Local: Banking Churn Notebook Model(LR)\")\n",
    "val saved_model = client.models.save(model_artifact).get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *(Optional - requires WML service and credentials)* Deploy in Cloud:  Create online deployment of published model in IBM Cloud WML Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// TODO:  This lab step is optional, do not run this cell unless you have WML credentials and have updated the WML credentials in the cell above.\n",
    "\n",
    "// Reload saved model\n",
    "val model_version_href = saved_model.meta.prop(\"modelVersionHref\").get\n",
    "val loaded_model_artifact = client.models.version(model_version_href).get\n",
    "\n",
    "// Get WML service instance token\n",
    "val wml_auth_header = \"Basic \" + Base64.getEncoder.encodeToString((username + \":\" + password).getBytes(StandardCharsets.UTF_8))\n",
    "val wml_url = service_path + \"/v3/identity/token\"\n",
    "val wml_response = Http(wml_url).header(\"Authorization\", wml_auth_header).asString\n",
    "val wmltoken_json: JsValue = Json.parse(wml_response.body)\n",
    "\n",
    "val wmltoken = (wmltoken_json \\ \"token\").asOpt[String] match {\n",
    "    case Some(x) => x\n",
    "    case None => \"\"\n",
    "}\n",
    "wmltoken\n",
    "\n",
    "// Get published_models url from instance details\n",
    "val endpoint_instance = service_path + \"/v3/wml_instances/\" + instance_id\n",
    "val wml_response_instance = Http(endpoint_instance).header(\"Content-Type\", \"application/json\").header(\"Authorization\", \"Bearer \" + wmltoken).option(HttpOptions.connTimeout(10000)).option(HttpOptions.readTimeout(50000)).asString\n",
    "wml_response_instance\n",
    "val published_models_json: JsValue = Json.parse(wml_response_instance.body)\n",
    "val published_models_url = (((published_models_json \\ \"entity\") \\\\ \"published_models\")(0) \\ \"url\").as[JsString].value\n",
    "published_models_url\n",
    "\n",
    "//Get list of published models\n",
    "val wml_models = Http(published_models_url).header(\"Content-Type\", \"application/json\").header(\"Authorization\", \"Bearer \" + wmltoken).option(HttpOptions.connTimeout(10000)).option(HttpOptions.readTimeout(50000)).asString\n",
    "wml_models\n",
    "var deployment_endpoint: String = _\n",
    "wml_models.body.split(\"\\\"\").map{ s => {if ((s contains \"deployments\") & (s contains saved_model.uid.mkString)) {deployment_endpoint = s}}}\n",
    "deployment_endpoint\n",
    "\n",
    "//Create online deployment for published model\n",
    "val payload_name = \"From DSX Local:  Deployed Banking Churn Notebook Model(LR)\"\n",
    "val payload_data_online = Json.stringify(Json.toJson(Map(\"type\" -> \"online\", \"name\" -> payload_name)))\n",
    "val response_online = Http(deployment_endpoint).postData(payload_data_online).header(\"Content-Type\", \"application/json\").header(\"Authorization\", \"Bearer \" + wmltoken).option(HttpOptions.connTimeout(50000)).option(HttpOptions.readTimeout(50000)).asString\n",
    "print (response_online)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *(Optional - requires WML service and credentials)* Use IBM Cloud WML scoring service to classify data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// TODO:  This lab step is optional, do not run this cell unless you have WML credentials and have updated the WML credentials in the cell above.\n",
    "val scoring_href_json: JsValue = Json.parse(response_online.body)\n",
    "\n",
    "val scoring_href = (scoring_href_json \\ \"entity\" \\ \"scoring_url\").asOpt[String] match {\n",
    "    case Some(x) => x\n",
    "    case None => \"\"\n",
    "}\n",
    "\n",
    "print(scoring_href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// TODO:  This lab step is optional, do not run this cell unless you have WML credentials and have updated the WML credentials in the cell above.\n",
    "val fields_json =  Json.toJson(List(Json.toJson(\"AGE\"), \n",
    "                                    Json.toJson(\"ACTIVITY\"), \n",
    "                                    Json.toJson(\"EDUCATION\"), \n",
    "                                    Json.toJson(\"GENDER\"), \n",
    "                                    Json.toJson(\"STATE\"),\n",
    "                                    Json.toJson(\"NEGTWEETS\"), \n",
    "                                    Json.toJson(\"INCOME\")))\n",
    "val record_json = Json.toJson(List(Json.toJson(List(Json.toJson(23), \n",
    "                                                    Json.toJson(3), \n",
    "                                                    Json.toJson(\"Masters degree\"), \n",
    "                                                    Json.toJson(\"M\"), \n",
    "                                                    Json.toJson(\"NY\"), \n",
    "                                                    Json.toJson(7), \n",
    "                                                    Json.toJson(878657)))))\n",
    "val json_map = Json.toJson(Map(\"fields\" -> fields_json, \"values\" -> record_json))\n",
    "print(json_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// TODO:  This lab step is optional, do not run this cell unless you have WML credentials and have updated the WML credentials in the cell above.\n",
    "val payload_scoring = Json.stringify(json_map)\n",
    "val response_scoring = Http(scoring_href).postData(payload_scoring).header(\"Content-Type\", \"application/json\").header(\"Authorization\", \"Bearer \" + wmltoken).option(HttpOptions.method(\"POST\")).asString\n",
    "print(response_scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Developed by Alexander Petrov, Matt Walli, Analytics Technology Acceleration Team, IBM Analytics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "file_extension": ".scala",
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
